---
layout: about
title: About
permalink: /
#subtitle: <a href='#'>Affiliations</a>. Address. Contacts. Moto. Etc.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>sgao@cs.fsu.edu</p>
    <p>[<a href="https://scholar.google.com/citations?user=9mNI83oAAAAJ&hl=en">Google Scholar</a>]</p>
    <p>[<a href="https://www.linkedin.com/in/shangqian-gao-864217141/">Linkedin</a>]</p>
	<p>171 Love Building
	1017 Academic Way
	Department of Computer Science
	Florida State University
	Tallahassee, FL 32304
	United States</p>

news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---

I am an Assistant Professor in the Department of Computer Science at Florida State University. Before joining FSU, I worked as a Research Scientist at Samsung Research America, where I focused on enhancing the efficiency of Large Language Models. I earned my Ph.D. in Electrical and Computer Engineering from the Swanson School of Engineering at the University of Pittsburgh in 2024, under the supervision of Prof. Heng Huang. Before that, I obtained my M.S. degree in Computer Systems Engineering from Northeastern University in 2017 and my B.S. degree in Electronic Engineering from Xidian University in 2015.

My research interests includes: 
<ul>
    <li>Scalable Machine Learning:  Model compression for Deep Neural Networks (DNNs) and Large Language Models (LLMs). Differentiable Neural Architecture Search. 
	[<a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Gao_Discrete_Model_Compression_With_Resource_Constraint_for_Deep_Neural_Networks_CVPR_2020_paper.html">CVPR20</a>, 
	<a href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Network_Pruning_via_Performance_Maximization_CVPR_2021_paper.html">CVPR21</a>, 
	<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Zhang_Exploration_and_Estimation_for_Model_Compression_ICCV_2021_paper.html">ICCV21</a>, 
	<a href="https://link.springer.com/chapter/10.1007/978-3-031-20083-0_20">ECCV22</a>, 
	<a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9mNI83oAAAAJ&cstart=20&pagesize=80&citation_for_view=9mNI83oAAAAJ:-f6ydRqryjwC">ICCV23</a>, 
	<a href="https://alii-ganjj.github.io/assets/pdf/EffConv.pdf">AAAI23</a>] </li>
    <li>Efficient and Safe Cross-Modal Learning: Adversarial attack and defense on cross-modal datas. Efficient vision and language transformers and cross-modal DNNs. 
	[<a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Cross_Domain_Model_Compression_by_Structurally_Weight_Sharing_CVPR_2019_paper.html">CVPR19</a>, 
	<a href="https://proceedings.neurips.cc/paper/2019/hash/d384dec9f5f7a64a36b5c8f03b8a6d92-Abstract.html">NeurIPS19</a>, 
	<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Li_Adversarial_Attack_on_Deep_Cross-Modal_Hamming_Retrieval_ICCV_2021_paper.html">ICCV21</a>,
	<a href="https://openreview.net/pdf?id=UMERaIHMwB3">ICLR23</a>] </li>
    <li>Policy Gradient Methods for Reinforcement Learning: Variance-reduced policy gradient methods based on momentum techniques and mirror descent. 
	[<a href="https://proceedings.mlr.press/v119/huang20a/huang20a.pdf">ICML20</a>,
	<a href="https://arxiv.org/pdf/2106.12112.pdf">ICLR22</a>]</li>
	<li>Zeroth-order optimization methods and other topics for optimization. 
	[<a href="https://www.jmlr.org/papers/volume23/20-924/20-924.pdf">JMLR</a>,
	<a href="https://arxiv.org/pdf/2010.06097.pdf">TPAMI</a>,
	<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/b9e98316cb72fee82cc1160da5810abc-Paper-Conference.pdf">NeurIPS22</a>] 
	Fairness in deep learning and interpretation guided models. [<a href="https://par.nsf.gov/servlets/purl/10398060">ECCV22a</a>,
	<a href="https://arxiv.org/pdf/2209.02869.pdf">ECCV22b</a>]</li>
</ul>
